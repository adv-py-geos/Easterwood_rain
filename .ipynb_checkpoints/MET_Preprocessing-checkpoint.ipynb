{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column List\n",
    "name_list = [\"Station ID\",\"Date [UTC]\",\"Temp [F]\",\"DP [F]\",\"RH [%]\",\"W Dir [Deg]\",\"W Spd [Kts]\",\"Alt [inHg]\",\"1Hr-Prcp [mm]\",\n",
    "             \"Vis [mi]\",\"SKC1\",\"SKC2\",\"SKC3\",\"Cld Hgt1 [Ft]\",\"Cld Hgt2 [Ft]\",\"Cld Hgt3 [Ft]\",\"Prs Wx\"]\n",
    "\n",
    "# Data Type List\n",
    "dtype_list = {\"Station ID\":\"str\",\"UTC\":\"str\",\"Temp [F]\":\"float64\",\"DP [F]\":\"float64\",\"RH [%]\":\"float64\",\"W Dir [Deg]\":\"float64\",\n",
    "              \"W Spd [Kts]\":\"float64\",\"Alt [inHg]\":\"float64\",\"1Hr-Prcp [mm]\":\"float64\",\"Vis [mi]\":\"float64\",\"SKC1\":\"str\",\n",
    "              \"SKC2\":\"str\",\"SKC3\":\"str\",\"Cld Hgt1 [Ft]\":\"float64\",\"Cld Hgt2 [Ft]\":\"float64\",\"Cld Hgt3 [Ft]\":\"float64\",\n",
    "              \"Prs Wx\" : \"str\"}\n",
    "\n",
    "# Date Column\n",
    "parse_date = [\"Date [UTC]\"]\n",
    "\n",
    "# Import TxT Data\n",
    "CLL = pd.read_csv('Data/CLL.txt', sep='\\t', header=0, names = name_list, dtype = dtype_list, parse_dates = parse_date, index_col = 1).resample('1d').mean()\n",
    "DFW = pd.read_csv('Data/DFW.txt', sep='\\t', header=0, names = name_list, dtype = dtype_list, parse_dates = parse_date, index_col = 1).resample('1d').mean()\n",
    "AUS = pd.read_csv('Data/AUS.txt', sep='\\t', header=0, names = name_list, dtype = dtype_list, parse_dates = parse_date, index_col = 1).resample('1d').mean()\n",
    "IAH = pd.read_csv('Data/IAH.txt', sep='\\t', header=0, names = name_list, dtype = dtype_list, parse_dates = parse_date, index_col = 1).resample('1d').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prep:\n",
    "    \n",
    "    def fill_missing(dataframe, method='linear'):\n",
    "        if method == 'linear':\n",
    "            for i in dataframe.columns:\n",
    "                mask = np.isnan(dataframe[i])\n",
    "                dataframe[i][mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), dataframe[i][~mask])\n",
    "            return dataframe\n",
    "        \n",
    "    def howdy(dataframe):\n",
    "        # boolean transform of precipitation\n",
    "#         prcp = np.zeros(dataframe.shape[0])\n",
    "#         for i in range(dataframe.shape[0]):\n",
    "#             if dataframe['1Hr-Prcp [mm]'][i] > 0:\n",
    "#                 prcp[i] = 1\n",
    "#         print(dataframe)\n",
    "        dataframe = dataframe.assign(prcp=abs(dataframe['1Hr-Prcp [mm]'])!=-dataframe['1Hr-Prcp [mm]'])\n",
    "        return dataframe\n",
    "    \n",
    "    def norm(dataframe, method='standard'):\n",
    "        if method == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "            for i in dataframe:\n",
    "                dataframe = scaler.fit_transform(dataframe)\n",
    "            return dataframe\n",
    "        \n",
    "    def inverse(data):\n",
    "        return scaler.inverse_transofrm(data)\n",
    "    \n",
    "    def train_test(dataset, his = 0.9):\n",
    "    # split into train and test sets\n",
    "        train_size = int(len(dataset) * his)\n",
    "        test_size = len(dataset) - train_size\n",
    "        train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "        return train, test\n",
    "    \n",
    "    def split(data, n_steps):\n",
    "        X, y = list(), list()\n",
    "        for i in range(len(data)):\n",
    "            end_ix = i + n_steps\n",
    "            if end_ix > len(data):\n",
    "                break\n",
    "            seq_x, seq_y = data[i:end_ix, :], data[end_ix-1, 6]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)\n",
    "        return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = ['CLL', 'DFW', 'IAH', 'AUS']\n",
    "for airport in airports:\n",
    "    airport = eval(airport)\n",
    "    airport = Prep.fill_missing(airport) # fill NaNs\n",
    "#     airport= Prep.norm(airport) # normalize data\n",
    "#     airport = Prep.howdy(airport)\n",
    "\n",
    "# 1,2,3 days data, e.g. CLL\n",
    "CLL_n = Prep.norm(CLL)\n",
    "train, test = Prep.train_test(CLL_n)\n",
    "his_1, target_1 = Prep.split(train, 1)\n",
    "his_2, target_2 = Prep.split(train, 2)\n",
    "his_3, target_3 = Prep.split(train, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
